{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5a742c-de24-4e14-b3b7-fecf61ab2b50",
   "metadata": {},
   "source": [
    "# Text Analytics & Sentiment Scoring for Blog Articles\n",
    "This notebook performs:\n",
    "1. Web scraping to extract articles from given URLs.\n",
    "2. Text analysis including sentiment, readability, and linguistic features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8136e17-7abe-4a3f-b5ff-a512885a7946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (2.3.0)\n",
      "Requirement already satisfied: requests in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (4.13.4)\n",
      "Requirement already satisfied: openpyxl in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from beautifulsoup4) (4.14.0)\n",
      "Requirement already satisfied: et-xmlfile in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Pranshu/Desktop/Projects/assignment /venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Run this once if not already installed\n",
    "!pip install pandas requests beautifulsoup4 openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49f2c83b-0e9a-4154-95e7-860cf6a3b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Pranshu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the libraries \n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08446c7-72e2-4bf3-83c1-5b92206dc43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...\n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...\n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...\n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...\n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the list of URLs and URL_IDs\n",
    "input_df = pd.read_excel(\"../Data/Input.xlsx\")\n",
    "input_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61a00dc-65b2-4a30-92ce-03a6c8c097d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save the article text files\n",
    "output_folder = \"extracted_articles\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656851c7-18aa-47ac-a012-859255cbba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract title\n",
    "        title_tag = soup.find('h1')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
    "\n",
    "        #extract only the main content area\n",
    "        main_content = (\n",
    "            soup.find(\"div\", class_=\"td-post-content\") or \n",
    "            soup.find(\"article\") or\n",
    "            soup.find(\"div\", class_=\"post-content\") or\n",
    "            soup.find(\"div\", class_=\"blog-content\") or\n",
    "            soup  # fallback \n",
    "        )\n",
    "\n",
    "        # Extract all paragraph tags from that section\n",
    "        article_tags = main_content.find_all('p')\n",
    "        article_text = ' '.join([tag.get_text(strip=True) for tag in article_tags])\n",
    "\n",
    "        return title + \"\\n\\n\" + article_text\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to extract from URL: {url} | Error: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78733cff-bf3e-4d2b-85f2-42519d6047b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: Netclan20241017.txt\n",
      " Saved: Netclan20241018.txt\n",
      " Saved: Netclan20241019.txt\n",
      " Saved: Netclan20241020.txt\n",
      " Saved: Netclan20241021.txt\n",
      " Saved: Netclan20241022.txt\n",
      " Saved: Netclan20241023.txt\n",
      " Saved: Netclan20241024.txt\n",
      " Saved: Netclan20241025.txt\n",
      " Saved: Netclan20241026.txt\n",
      " Saved: Netclan20241027.txt\n",
      " Saved: Netclan20241028.txt\n",
      " Saved: Netclan20241029.txt\n",
      " Saved: Netclan20241030.txt\n",
      " Saved: Netclan20241031.txt\n",
      " Saved: Netclan20241032.txt\n",
      " Saved: Netclan20241033.txt\n",
      " Saved: Netclan20241034.txt\n",
      " Saved: Netclan20241035.txt\n",
      " Saved: Netclan20241036.txt\n",
      " Saved: Netclan20241037.txt\n",
      " Saved: Netclan20241038.txt\n",
      " Saved: Netclan20241039.txt\n",
      " Saved: Netclan20241040.txt\n",
      " Saved: Netclan20241041.txt\n",
      " Saved: Netclan20241042.txt\n",
      " Saved: Netclan20241043.txt\n",
      " Saved: Netclan20241044.txt\n",
      " Saved: Netclan20241045.txt\n",
      " Saved: Netclan20241046.txt\n",
      " Saved: Netclan20241047.txt\n",
      " Saved: Netclan20241048.txt\n",
      " Saved: Netclan20241049.txt\n",
      " Saved: Netclan20241050.txt\n",
      " Saved: Netclan20241051.txt\n",
      " Saved: Netclan20241052.txt\n",
      " Saved: Netclan20241053.txt\n",
      " Saved: Netclan20241054.txt\n",
      " Saved: Netclan20241055.txt\n",
      " Saved: Netclan20241056.txt\n",
      " Saved: Netclan20241057.txt\n",
      " Saved: Netclan20241058.txt\n",
      " Saved: Netclan20241059.txt\n",
      " Saved: Netclan20241060.txt\n",
      " Saved: Netclan20241061.txt\n",
      " Saved: Netclan20241062.txt\n",
      " Saved: Netclan20241063.txt\n",
      " Saved: Netclan20241064.txt\n",
      " Saved: Netclan20241065.txt\n",
      " Saved: Netclan20241066.txt\n",
      " Saved: Netclan20241067.txt\n",
      " Saved: Netclan20241068.txt\n",
      " Saved: Netclan20241069.txt\n",
      " Saved: Netclan20241070.txt\n",
      " Saved: Netclan20241071.txt\n",
      " Saved: Netclan20241072.txt\n",
      " Saved: Netclan20241073.txt\n",
      " Saved: Netclan20241074.txt\n",
      " Saved: Netclan20241075.txt\n",
      " Saved: Netclan20241076.txt\n",
      " Saved: Netclan20241077.txt\n",
      " Saved: Netclan20241078.txt\n",
      " Saved: Netclan20241079.txt\n",
      " Saved: Netclan20241080.txt\n",
      " Saved: Netclan20241081.txt\n",
      " Saved: Netclan20241082.txt\n",
      " Saved: Netclan20241083.txt\n",
      " Saved: Netclan20241084.txt\n",
      " Saved: Netclan20241085.txt\n",
      " Saved: Netclan20241086.txt\n",
      " Saved: Netclan20241087.txt\n",
      " Saved: Netclan20241088.txt\n",
      " Saved: Netclan20241089.txt\n",
      " Failed to extract from URL: https://insights.blackcoffer.com/trading-bot-for-forex/ | Error: HTTPSConnectionPool(host='insights.blackcoffer.com', port=443): Read timed out. (read timeout=10)\n",
      " Skipped: Netclan20241090\n",
      " Saved: Netclan20241091.txt\n",
      " Saved: Netclan20241092.txt\n",
      " Saved: Netclan20241093.txt\n",
      " Saved: Netclan20241094.txt\n",
      " Saved: Netclan20241095.txt\n",
      " Saved: Netclan20241096.txt\n",
      " Saved: Netclan20241097.txt\n",
      " Saved: Netclan20241098.txt\n",
      " Saved: Netclan20241099.txt\n",
      " Saved: Netclan20241100.txt\n",
      " Saved: Netclan20241101.txt\n",
      " Saved: Netclan20241102.txt\n",
      " Saved: Netclan20241103.txt\n",
      " Saved: Netclan20241104.txt\n",
      " Saved: Netclan20241105.txt\n",
      " Saved: Netclan20241106.txt\n",
      " Saved: Netclan20241107.txt\n",
      " Saved: Netclan20241108.txt\n",
      " Saved: Netclan20241109.txt\n",
      " Saved: Netclan20241110.txt\n",
      " Saved: Netclan20241111.txt\n",
      " Saved: Netclan20241112.txt\n",
      " Saved: Netclan20241113.txt\n",
      " Saved: Netclan20241114.txt\n",
      " Saved: Netclan20241115.txt\n",
      " Saved: Netclan20241116.txt\n",
      " Saved: Netclan20241117.txt\n",
      " Saved: Netclan20241118.txt\n",
      " Saved: Netclan20241119.txt\n",
      " Saved: Netclan20241120.txt\n",
      " Saved: Netclan20241121.txt\n",
      " Saved: Netclan20241122.txt\n",
      " Saved: Netclan20241123.txt\n",
      " Saved: Netclan20241124.txt\n",
      " Saved: Netclan20241125.txt\n",
      " Saved: Netclan20241126.txt\n",
      " Saved: Netclan20241127.txt\n",
      " Saved: Netclan20241128.txt\n",
      " Saved: Netclan20241129.txt\n",
      " Saved: Netclan20241130.txt\n",
      " Saved: Netclan20241131.txt\n",
      " Saved: Netclan20241132.txt\n",
      " Saved: Netclan20241133.txt\n",
      " Saved: Netclan20241134.txt\n",
      " Saved: Netclan20241135.txt\n",
      " Saved: Netclan20241136.txt\n",
      " Saved: Netclan20241137.txt\n",
      " Saved: Netclan20241138.txt\n",
      " Saved: Netclan20241139.txt\n",
      " Saved: Netclan20241140.txt\n",
      " Saved: Netclan20241141.txt\n",
      " Saved: Netclan20241142.txt\n",
      " Saved: Netclan20241143.txt\n",
      " Saved: Netclan20241144.txt\n",
      " Saved: Netclan20241145.txt\n",
      " Saved: Netclan20241146.txt\n",
      " Saved: Netclan20241147.txt\n",
      " Saved: Netclan20241148.txt\n",
      " Saved: Netclan20241149.txt\n",
      " Saved: Netclan20241150.txt\n",
      " Saved: Netclan20241151.txt\n",
      " Saved: Netclan20241152.txt\n",
      " Saved: Netclan20241153.txt\n",
      " Saved: Netclan20241154.txt\n",
      " Saved: Netclan20241155.txt\n",
      " Saved: Netclan20241156.txt\n",
      " Saved: Netclan20241157.txt\n",
      " Saved: Netclan20241158.txt\n",
      " Saved: Netclan20241159.txt\n",
      " Saved: Netclan20241160.txt\n",
      " Saved: Netclan20241161.txt\n",
      " Saved: Netclan20241162.txt\n",
      " Saved: Netclan20241163.txt\n"
     ]
    }
   ],
   "source": [
    "# Loop over all URLs and save content in .txt files\n",
    "for index, row in input_df.iterrows():\n",
    "    url_id = str(row['URL_ID'])\n",
    "    url = row['URL']\n",
    "    \n",
    "    content = extract_article(url)\n",
    "    \n",
    "    if content:\n",
    "        file_path = os.path.join(output_folder, f\"{url_id}.txt\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        print(f\" Saved: {url_id}.txt\")\n",
    "    else:\n",
    "        print(f\" Skipped: {url_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07b682be-2371-4577-b558-9a9b983d18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords from your single file\n",
    "with open('./StopWords/stopwords.txt', 'r') as f:\n",
    "    stop_words = set([line.strip().lower() for line in f if line.strip()])\n",
    "\n",
    "# Load positive words\n",
    "with open('./MasterDictionary/positive-words.txt', 'r') as f:\n",
    "    positive_words = set([line.strip().lower() for line in f if line.strip()])\n",
    "\n",
    "# Load negative words\n",
    "with open('./MasterDictionary/negative-words.txt', 'r') as f:\n",
    "    negative_words = set([line.strip().lower() for line in f if line.strip()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ea26ac1-1856-44d3-9e15-3529e822b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    meaningful_words = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    \n",
    "    return meaningful_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee10d22-1920-4ce3-8e39-41e2db6731f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(tokens):\n",
    "    pos_score = sum(1 for word in tokens if word in positive_words)\n",
    "    neg_score = sum(1 for word in tokens if word in negative_words)\n",
    "    \n",
    "    polarity_score = (pos_score - neg_score) / ((pos_score + neg_score) + 0.000001)\n",
    "    subjectivity_score = (pos_score + neg_score) / (len(tokens) + 0.000001)\n",
    "    \n",
    "    return pos_score, neg_score, polarity_score, subjectivity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cd3d714-c9d9-4b8e-995e-a23580ac4b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241024</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241030</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.076271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241144</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.538461</td>\n",
       "      <td>0.117117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  \\\n",
       "0  Netclan20241024               9               2        0.636364   \n",
       "1  Netclan20241030              13               5        0.444444   \n",
       "2  Netclan20241018              13               7        0.300000   \n",
       "3  Netclan20241150               2               2        0.000000   \n",
       "4  Netclan20241144              10               3        0.538461   \n",
       "\n",
       "   SUBJECTIVITY SCORE  \n",
       "0            0.073333  \n",
       "1            0.076271  \n",
       "2            0.051282  \n",
       "3            0.044444  \n",
       "4            0.117117  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for filename in os.listdir('extracted_articles'):\n",
    "    if filename.endswith('.txt'):\n",
    "        url_id = filename.split('.')[0]\n",
    "        \n",
    "        with open(os.path.join('extracted_articles', filename), 'r', encoding='utf-8') as file:\n",
    "            full_text = file.read()\n",
    "            \n",
    "            # Clean and tokenize\n",
    "            tokens = clean_text(full_text)\n",
    "            \n",
    "            # Calculate scores\n",
    "            pos_score, neg_score, polarity, subjectivity = sentiment_scores(tokens)\n",
    "            \n",
    "            results.append({\n",
    "                'URL_ID': url_id,\n",
    "                'POSITIVE SCORE': pos_score,\n",
    "                'NEGATIVE SCORE': neg_score,\n",
    "                'POLARITY SCORE': polarity,\n",
    "                'SUBJECTIVITY SCORE': subjectivity\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "scores_df = pd.DataFrame(results)\n",
    "scores_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eef9da0-8b8d-414d-be56-b198190858cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count syllables in a word\n",
    "def count_syllables(word):\n",
    "    word = word.lower()\n",
    "    vowels = 'aeiou'\n",
    "    count = 0\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for i in range(1, len(word)):\n",
    "        if word[i] in vowels and word[i - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"es\") or word.endswith(\"ed\"):\n",
    "        count -= 1\n",
    "    return max(count, 1)\n",
    "\n",
    "# Check if a word is complex (more than 2 syllables)\n",
    "def is_complex_word(word):\n",
    "    return count_syllables(word) > 2\n",
    "\n",
    "# Count personal pronouns using regex\n",
    "def count_personal_pronouns(text):\n",
    "    pronouns = re.findall(r'\\b(I|we|my|ours|us)\\b', text, flags=re.I)\n",
    "    return len(pronouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66ca954a-dcbb-481b-9cdb-23df0755fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_metrics(text, tokens):\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Sentence stats\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(tokens)\n",
    "    avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
    "    \n",
    "    # Complex words\n",
    "    complex_words = [word for word in tokens if is_complex_word(word)]\n",
    "    complex_word_count = len(complex_words)\n",
    "    percent_complex_words = complex_word_count / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Fog index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percent_complex_words)\n",
    "    \n",
    "    # Syllables per word\n",
    "    syllable_count = sum(count_syllables(word) for word in tokens)\n",
    "    syllable_per_word = syllable_count / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Average word length\n",
    "    total_chars = sum(len(word) for word in tokens)\n",
    "    avg_word_length = total_chars / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Personal pronouns\n",
    "    personal_pronouns = count_personal_pronouns(text)\n",
    "    \n",
    "    return {\n",
    "        'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "        'PERCENTAGE OF COMPLEX WORDS': percent_complex_words,\n",
    "        'FOG INDEX': fog_index,\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE': avg_sentence_length,  # same value\n",
    "        'COMPLEX WORD COUNT': complex_word_count,\n",
    "        'WORD COUNT': num_words,\n",
    "        'SYLLABLE PER WORD': syllable_per_word,\n",
    "        'PERSONAL PRONOUNS': personal_pronouns,\n",
    "        'AVG WORD LENGTH': avg_word_length\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db6d46e7-9e1b-4061-a79f-96b535f46c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>8.359350</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>49</td>\n",
       "      <td>123</td>\n",
       "      <td>2.292683</td>\n",
       "      <td>1</td>\n",
       "      <td>7.569106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>4.465641</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>129</td>\n",
       "      <td>390</td>\n",
       "      <td>2.271795</td>\n",
       "      <td>7</td>\n",
       "      <td>7.125641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>7.625333</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>47</td>\n",
       "      <td>150</td>\n",
       "      <td>2.293333</td>\n",
       "      <td>1</td>\n",
       "      <td>7.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>0.543011</td>\n",
       "      <td>5.728315</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>202</td>\n",
       "      <td>372</td>\n",
       "      <td>2.612903</td>\n",
       "      <td>4</td>\n",
       "      <td>8.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.396396</td>\n",
       "      <td>5.091892</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>44</td>\n",
       "      <td>111</td>\n",
       "      <td>2.450450</td>\n",
       "      <td>1</td>\n",
       "      <td>7.468468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  \\\n",
       "137  Netclan20241017               5               0        1.000000   \n",
       "2    Netclan20241018              13               7        0.300000   \n",
       "7    Netclan20241019               9               2        0.636364   \n",
       "33   Netclan20241020              23              11        0.352941   \n",
       "26   Netclan20241021               2               0        1.000000   \n",
       "\n",
       "     SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  \\\n",
       "137            0.040650            20.500000                     0.398374   \n",
       "2              0.051282            10.833333                     0.330769   \n",
       "7              0.073333            18.750000                     0.313333   \n",
       "33             0.091398            13.777778                     0.543011   \n",
       "26             0.018018            12.333333                     0.396396   \n",
       "\n",
       "     FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  \\\n",
       "137   8.359350                         20.500000                  49   \n",
       "2     4.465641                         10.833333                 129   \n",
       "7     7.625333                         18.750000                  47   \n",
       "33    5.728315                         13.777778                 202   \n",
       "26    5.091892                         12.333333                  44   \n",
       "\n",
       "     WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "137         123           2.292683                  1         7.569106  \n",
       "2           390           2.271795                  7         7.125641  \n",
       "7           150           2.293333                  1         7.346667  \n",
       "33          372           2.612903                  4         8.096774  \n",
       "26          111           2.450450                  1         7.468468  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = []\n",
    "\n",
    "for filename in os.listdir('extracted_articles'):\n",
    "    if filename.endswith('.txt'):\n",
    "        url_id = filename.split('.')[0]\n",
    "        \n",
    "        with open(os.path.join('extracted_articles', filename), 'r', encoding='utf-8') as file:\n",
    "            full_text = file.read()\n",
    "            \n",
    "            # Clean text and tokenize\n",
    "            tokens = clean_text(full_text)\n",
    "            \n",
    "            # Sentiment scores\n",
    "            pos_score, neg_score, polarity, subjectivity = sentiment_scores(tokens)\n",
    "            \n",
    "            # Readability and other metrics\n",
    "            extra_metrics = analyze_text_metrics(full_text, tokens)\n",
    "            \n",
    "            # Combine all results\n",
    "            result = {\n",
    "                'URL_ID': url_id,\n",
    "                'POSITIVE SCORE': pos_score,\n",
    "                'NEGATIVE SCORE': neg_score,\n",
    "                'POLARITY SCORE': polarity,\n",
    "                'SUBJECTIVITY SCORE': subjectivity\n",
    "            }\n",
    "            result.update(extra_metrics)\n",
    "            \n",
    "            final_results.append(result)\n",
    "\n",
    "# Create final DataFrame\n",
    "final_df = pd.DataFrame(final_results)\n",
    "final_df = final_df.sort_values('URL_ID')\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f40849-e108-40ba-acac-e0cc5c5a3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output with URL saved to 'Output Data Structure.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Merge URL_ID and URL from already loaded input_df\n",
    "final_df = pd.merge(input_df[['URL_ID', 'URL']], final_df, on='URL_ID', how='left')\n",
    "\n",
    "# Save the final file\n",
    "final_df.to_excel(\"Output Data Structure.xlsx\", index=False)\n",
    "print(\"Final output with URL saved to 'Output Data Structure.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fa47d-d662-47b3-87c3-8dd57bf22a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
